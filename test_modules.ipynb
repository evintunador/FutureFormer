{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ea126987-59aa-4f76-b926-6d632887c30b",
   "metadata": {},
   "source": [
    "# This notebook is designed for teaching/testing purposes to help you visualize the tensor shapes that go through each module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f833b1f8-ea91-4ae5-b3a3-73e08e4c8c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my virtual environments are rarely properly connected to jupyter so this fixes that. \n",
    "# you prolly won't need this cell but running it won't hurt anything either\n",
    "import sys\n",
    "import os\n",
    "current_dir = os.getcwd()  # Get the current working directory\n",
    "venv_dir = os.path.join(current_dir, 'venv') \n",
    "python_version = str(sys.version_info.major) + '.' + str(sys.version_info.minor)\n",
    "site_packages_path = os.path.join(venv_dir, 'lib', 'python' + python_version, 'site-packages')\n",
    "sys.path.append(site_packages_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72c2c04f-2dbd-4020-8d91-cc0e4e8511b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ModelConfig(dim=32, device='cpu', dropout_rate=0.1, weight_tying=True, tokenizer='bpe_v2', vocab_len=1024, num_layers=6, second_resid_norm=False, mlp_hidden_mult=4, mlp_bias=False, mlp_nonlinearity='SiLU', mlp_gated=True, num_q_heads=2, num_kv_heads=1, head_dim=16, theta=10000, max_seq_len=128, ca_num_q_heads=2, ca_num_kv_heads=1, ca_head_dim=16, scale_first_resid=True, norm_type='RMSNorm', norm_affine=True, norm_bias=True, eps=1e-06, pool_type='sum', pre_pool_norm=True, pool_output_linear=False, pool_bias=False, compress_freq='constant', compress_freq_n=1, fs_mult=4, fs_periods=3, fs_loss_lambda=1.0, max_batch_size=1)\n"
     ]
    }
   ],
   "source": [
    "# config file\n",
    "from config import ModelConfig\n",
    "cfg = ModelConfig()\n",
    "print(cfg)\n",
    "\n",
    "# import the tokenizer specified by cfg\n",
    "from tools import import_from_nested_path\n",
    "imported_objects = import_from_nested_path(['tokenizers', cfg.tokenizer], 'tokenizer', ['get_tokenizer'])\n",
    "get_tokenizer = imported_objects.get('get_tokenizer')\n",
    "tokenizer = get_tokenizer(size = 512) # assuming 'bpe', size options are 95, 128, 256, 512, 1024 and 2048\n",
    "\n",
    "import random\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c12e3b-dc63-4479-ad55-b05d96364d1f",
   "metadata": {},
   "source": [
    "# Norms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3debc7b1-a7ec-4fb3-98cb-d16edf7c71cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.norm import Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "627969e9-9017-43f3-90ec-9a485abef26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.064 K parameters\n",
      "Norm()\n",
      "\n",
      "==========Entering Norm.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "\n",
      "==========Entering Norm.RMSNorm==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Norm.RMSNorm==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Norm.forward==========\n",
      "CPU times: user 3.42 ms, sys: 1.5 ms, total: 4.91 ms\n",
      "Wall time: 3.57 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "### RMSNorm\n",
    "\n",
    "# Create an instance of RMSNorm\n",
    "module = Norm(cfg.dim, 'RMSNorm').to(cfg.device)\n",
    "\n",
    "# let's take a look\n",
    "print(sum(p.numel() for p in module.parameters())/1e3, 'K parameters')\n",
    "print(module)\n",
    "\n",
    "# Initially, logging is disabled by default\n",
    "module.enable_logging()\n",
    "\n",
    "### Optionally disabling printing for sub-functions\n",
    "#module.disable_function_logging('CosineNorm')\n",
    "#module.disable_function_logging('LayerNorm')\n",
    "#module.disable_function_logging('RMSNorm')\n",
    "\n",
    "x = torch.randn(32,cfg.max_seq_len,cfg.dim).to(cfg.device)\n",
    "\n",
    "# Call the forward method - logging will occur\n",
    "output = module(x)\n",
    "\n",
    "# Disable logging. \n",
    "# This isn't actually necessary since we won't be using this object again but that's how you'd do it\n",
    "module.disable_logging()\n",
    "\n",
    "# clearing up ram jic we're training later\n",
    "del module, x, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64020a96-205a-45b7-ae56-a3555d2b3719",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering Norm.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "\n",
      "==========Entering Norm.LayerNorm==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Norm.LayerNorm==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Norm.forward==========\n",
      "CPU times: user 7.52 ms, sys: 1.48 ms, total: 9 ms\n",
      "Wall time: 4.56 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# LayerNorm\n",
    "module = Norm(cfg.dim, 'LayerNorm').to(cfg.device)\n",
    "module.enable_logging()\n",
    "\n",
    "### Optionally disabling printing for sub-functions\n",
    "#module.disable_function_logging('CosineNorm')\n",
    "#module.disable_function_logging('LayerNorm')\n",
    "#module.disable_function_logging('RMSNorm')\n",
    "\n",
    "x = torch.randn(32,cfg.max_seq_len,cfg.dim).to(cfg.device)\n",
    "output = module(x)\n",
    "module.disable_logging()\n",
    "del module, x, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e190f3de-37fd-442b-bfb1-6a090115fc75",
   "metadata": {},
   "source": [
    "# Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a89e1e8f-cedd-4885-ad50-934827ed045c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.mqa import MQA, futureSightMQA, precompute_freqs_cis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e8f27b4-6d1f-4fcd-99b0-2284e65d6b63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.072 K parameters\n",
      "MQA(\n",
      "  (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "  (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "  (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "  (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      ")\n",
      "\n",
      "==========Entering MQA.forward==========\n",
      "Inputs:\n",
      "Tensor 'q' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'k' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'v' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([128, 8])\n",
      "Tensor 'mask' shape: torch.Size([128, 128])\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Integer 'training': Value=True\n",
      "\n",
      "==========Entering MQA.apply_rotary_emb==========\n",
      "Inputs:\n",
      "Tensor 'q' shape: torch.Size([32, 128, 2, 16])\n",
      "Tensor 'k' shape: torch.Size([32, 128, 1, 16])\n",
      "Tensor 'freqs_cis' shape: torch.Size([128, 8])\n",
      "\n",
      "==========Entering MQA.reshape_for_broadcast==========\n",
      "Inputs:\n",
      "Tensor 'freqs_cis' shape: torch.Size([128, 8])\n",
      "Tensor 'x' shape: torch.Size([32, 128, 2, 8])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 128, 1, 8])\n",
      "==========Exiting MQA.reshape_for_broadcast==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 128, 2, 16])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 128, 1, 16])\n",
      "==========Exiting MQA.apply_rotary_emb==========\n",
      "\n",
      "==========Entering MQA.match_headcount==========\n",
      "Inputs:\n",
      "Tensor 'k' shape: torch.Size([32, 128, 1, 16])\n",
      "Tensor 'v' shape: torch.Size([32, 128, 1, 16])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 128, 2, 16])\n",
      "Tensor 'output[1]' shape: torch.Size([32, 128, 2, 16])\n",
      "==========Exiting MQA.match_headcount==========\n",
      "\n",
      "==========Entering MQA.attend==========\n",
      "Inputs:\n",
      "Tensor 'q' shape: torch.Size([32, 2, 128, 16])\n",
      "Tensor 'k' shape: torch.Size([32, 2, 128, 16])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 2, 128, 128])\n",
      "==========Exiting MQA.attend==========\n",
      "\n",
      "==========Entering MQA.calc_output==========\n",
      "Inputs:\n",
      "Tensor 'logits' shape: torch.Size([32, 2, 128, 128])\n",
      "Tensor 'v' shape: torch.Size([32, 2, 128, 16])\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting MQA.calc_output==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting MQA.forward==========\n",
      "CPU times: user 17.1 ms, sys: 10.6 ms, total: 27.7 ms\n",
      "Wall time: 16.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# first up let's look at self-attention training\n",
    "\n",
    "# Create an instance of multi-head self-attention\n",
    "module = MQA(\n",
    "        cfg.dim,\n",
    "        cfg.head_dim,\n",
    "        cfg.num_q_heads,\n",
    "        cfg.num_kv_heads,\n",
    "        cfg.max_seq_len,\n",
    "        #cfg.max_batch_size, # if you don't pass in a max_batch_size then the module will be incapable of kv caching\n",
    ").to(cfg.device)\n",
    "print(sum(p.numel() for p in module.parameters())/1e3, 'K parameters')\n",
    "print(module)\n",
    "\n",
    "# Initially, logging is disabled by default\n",
    "module.enable_logging()\n",
    "\n",
    "### Optionally disabling printing for sub-functions\n",
    "#module.disable_function_logging('apply_rotary_emb')\n",
    "#module.disable_function_logging('reshape_for_broadcast')\n",
    "#module.disable_function_logging('match_headcount')\n",
    "#module.disable_function_logging('attend')\n",
    "#module.disable_function_logging('calc_output')\n",
    "\n",
    "# precompute RoPE frequencies, causal mask, and dummy input data\n",
    "freqs_cis = precompute_freqs_cis(\n",
    "    cfg.head_dim,\n",
    "    cfg.max_seq_len,\n",
    "    cfg.theta\n",
    ").to(cfg.device)\n",
    "mask = torch.full(\n",
    "    (cfg.max_seq_len, cfg.max_seq_len),\n",
    "    float(\"-inf\"),\n",
    "    device=cfg.device\n",
    ")\n",
    "mask = torch.triu(mask, diagonal=1)\n",
    "x = torch.randn(32,cfg.max_seq_len,cfg.dim).to(cfg.device)\n",
    "\n",
    "# Call the forward method - logging will occur\n",
    "output = module(x, x, x, freqs_cis, mask, training=True)\n",
    "\n",
    "# Disable logging. \n",
    "# This isn't actually necessary since we won't be using this object again but that's how you'd do it\n",
    "module.disable_logging()\n",
    "\n",
    "# clearing up ram jic we're training later\n",
    "del module, freqs_cis, mask, x, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1e7e034c-c5a6-43ac-b6d2-bbb71f9965ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==========Entering MQA.forward==========\n",
      "Inputs:\n",
      "Tensor 'q' shape: torch.Size([1, 32, 32])\n",
      "Tensor 'k' shape: torch.Size([1, 32, 32])\n",
      "Tensor 'v' shape: torch.Size([1, 32, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([32, 8])\n",
      "Tensor 'mask' shape: torch.Size([32, 33])\n",
      "Integer 'cache_len': Value=1\n",
      "Integer 'training': Value=False\n",
      "\n",
      "==========Entering MQA.apply_rotary_emb==========\n",
      "Inputs:\n",
      "Tensor 'q' shape: torch.Size([1, 32, 2, 16])\n",
      "Tensor 'k' shape: torch.Size([1, 32, 1, 16])\n",
      "Tensor 'freqs_cis' shape: torch.Size([32, 8])\n",
      "\n",
      "==========Entering MQA.reshape_for_broadcast==========\n",
      "Inputs:\n",
      "Tensor 'freqs_cis' shape: torch.Size([32, 8])\n",
      "Tensor 'x' shape: torch.Size([1, 32, 2, 8])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 32, 1, 8])\n",
      "==========Exiting MQA.reshape_for_broadcast==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([1, 32, 2, 16])\n",
      "Tensor 'output[1]' shape: torch.Size([1, 32, 1, 16])\n",
      "==========Exiting MQA.apply_rotary_emb==========\n",
      "\n",
      "==========Entering MQA.match_headcount==========\n",
      "Inputs:\n",
      "Tensor 'k' shape: torch.Size([1, 33, 1, 16])\n",
      "Tensor 'v' shape: torch.Size([1, 33, 1, 16])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([1, 33, 2, 16])\n",
      "Tensor 'output[1]' shape: torch.Size([1, 33, 2, 16])\n",
      "==========Exiting MQA.match_headcount==========\n",
      "\n",
      "==========Entering MQA.attend==========\n",
      "Inputs:\n",
      "Tensor 'q' shape: torch.Size([1, 2, 32, 16])\n",
      "Tensor 'k' shape: torch.Size([1, 2, 33, 16])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 2, 32, 33])\n",
      "==========Exiting MQA.attend==========\n",
      "\n",
      "==========Entering MQA.calc_output==========\n",
      "Inputs:\n",
      "Tensor 'logits' shape: torch.Size([1, 2, 32, 33])\n",
      "Tensor 'v' shape: torch.Size([1, 2, 33, 16])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 32, 32])\n",
      "==========Exiting MQA.calc_output==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 32, 32])\n",
      "==========Exiting MQA.forward==========\n",
      "CPU times: user 2.11 ms, sys: 1.2 ms, total: 3.31 ms\n",
      "Wall time: 2.55 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# now let's do it for self-attention inference\n",
    "\n",
    "module = MQA(\n",
    "        cfg.dim,\n",
    "        cfg.head_dim,\n",
    "        cfg.num_q_heads,\n",
    "        cfg.num_kv_heads,\n",
    "        cfg.max_seq_len,\n",
    "        cfg.max_batch_size\n",
    ").to(cfg.device)\n",
    "module.enable_logging()\n",
    "#module.disable_function_logging('apply_rotary_emb')\n",
    "#module.disable_function_logging('reshape_for_broadcast')\n",
    "#module.disable_function_logging('match_headcount')\n",
    "#module.disable_function_logging('attend')\n",
    "#module.disable_function_logging('calc_output')\n",
    "\n",
    "# precompute RoPE frequencies, causal mask, and dummy input data\n",
    "freqs_cis = precompute_freqs_cis(\n",
    "    cfg.head_dim,\n",
    "    cfg.max_seq_len,\n",
    "    cfg.theta\n",
    ").to(cfg.device)\n",
    "mask = torch.full(\n",
    "    (cfg.max_seq_len, cfg.max_seq_len),\n",
    "    float(\"-inf\"),\n",
    "    device=cfg.device\n",
    ")\n",
    "mask = torch.triu(mask, diagonal=1)\n",
    "\n",
    "# setting up for kv caching\n",
    "context_chunk_len = cfg.max_seq_len // 4\n",
    "cache_len = random.randint(1, 3 * context_chunk_len)\n",
    "seq_len = cache_len + context_chunk_len\n",
    "# need to extend the mask with zeros for the cached values\n",
    "mask = mask[:context_chunk_len, :context_chunk_len]\n",
    "mask = torch.hstack(\n",
    "            [torch.zeros((context_chunk_len, cache_len)), mask]\n",
    "        )\n",
    "\n",
    "# these don't use seq_len because those entries should already be in the kv cache\n",
    "freqs_cis = freqs_cis[:context_chunk_len]\n",
    "x = torch.randn(cfg.max_batch_size,context_chunk_len,cfg.dim).to(cfg.device)\n",
    "\n",
    "# Call the forward method - logging will occur\n",
    "output = module(x, x, x, freqs_cis, mask, cache_len)\n",
    "\n",
    "# Disable logging. \n",
    "# This isn't actually necessary since we won't be using this object again but that's how you'd do it\n",
    "module.disable_logging()\n",
    "\n",
    "# clearing up ram jic we're training later\n",
    "del module, freqs_cis, mask, cache_len, context_chunk_len, seq_len, x, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6f6b9519-6021-4ec9-94c8-1cdaae31dc4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.072 K parameters\n",
      "futureSightMQA(\n",
      "  (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "  (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "  (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "  (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      ")\n",
      "\n",
      "==========Entering futureSightMQA.forward==========\n",
      "Inputs:\n",
      "Tensor 'q' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'kv' shape: torch.Size([32, 128, 2, 32])\n",
      "Integer 'training': Value=True\n",
      "\n",
      "==========Entering futureSightMQA.match_headcount==========\n",
      "Inputs:\n",
      "Tensor 'k' shape: torch.Size([4096, 2, 1, 16])\n",
      "Tensor 'v' shape: torch.Size([4096, 2, 1, 16])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([4096, 2, 2, 16])\n",
      "Tensor 'output[1]' shape: torch.Size([4096, 2, 2, 16])\n",
      "==========Exiting futureSightMQA.match_headcount==========\n",
      "\n",
      "==========Entering futureSightMQA.attend==========\n",
      "Inputs:\n",
      "Tensor 'q' shape: torch.Size([4096, 2, 1, 16])\n",
      "Tensor 'k' shape: torch.Size([4096, 2, 2, 16])\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([4096, 2, 1, 2])\n",
      "==========Exiting futureSightMQA.attend==========\n",
      "\n",
      "==========Entering futureSightMQA.calc_output==========\n",
      "Inputs:\n",
      "Tensor 'logits' shape: torch.Size([4096, 2, 1, 2])\n",
      "Tensor 'v' shape: torch.Size([4096, 2, 2, 16])\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([4096, 1, 32])\n",
      "==========Exiting futureSightMQA.calc_output==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting futureSightMQA.forward==========\n",
      "CPU times: user 10.7 ms, sys: 2.65 ms, total: 13.4 ms\n",
      "Wall time: 10 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# now cross-attention, which should be the same whether doing training or inference\n",
    "\n",
    "# Create an instance of future sight cross-attention\n",
    "module = futureSightMQA(\n",
    "        cfg.dim,\n",
    "        cfg.head_dim,\n",
    "        cfg.num_q_heads,\n",
    "        cfg.num_kv_heads,\n",
    "        cfg.max_seq_len\n",
    ").to(cfg.device)\n",
    "print(sum(p.numel() for p in module.parameters())/1e3, 'K parameters')\n",
    "print(module)\n",
    "\n",
    "# Initially, logging is disabled by default\n",
    "module.enable_logging()\n",
    "\n",
    "### Optionally disabling printing for sub-functions\n",
    "#module.disable_function_logging('match_headcount')\n",
    "#module.disable_function_logging('attend')\n",
    "#module.disable_function_logging('calc_output')\n",
    "\n",
    "x = torch.randn(32,cfg.max_seq_len,cfg.dim).to(cfg.device)\n",
    "z = torch.randn(32,cfg.max_seq_len,2,cfg.dim).to(cfg.device)\n",
    "\n",
    "# Call the forward method - logging will occur\n",
    "output = module(x, z, training=True)\n",
    "\n",
    "# clearing up ram jic we're training later\n",
    "del module, x, z, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb308c5-b578-46f2-86ae-bfa6800be641",
   "metadata": {},
   "source": [
    "# MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7736b685-f941-4182-a5b7-4731cce706b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.mlp import MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c62e49e9-2189-4269-968e-1df99469dc9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.16 K parameters\n",
      "MLP(\n",
      "  (Wup): Linear(in_features=32, out_features=85, bias=False)\n",
      "  (Wgate): Linear(in_features=32, out_features=85, bias=False)\n",
      "  (Wdown): Linear(in_features=85, out_features=32, bias=False)\n",
      "  (nonlinearity): GELU(approximate='none')\n",
      ")\n",
      "\n",
      "==========Entering MLP.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting MLP.forward==========\n",
      "CPU times: user 7.71 ms, sys: 3.11 ms, total: 10.8 ms\n",
      "Wall time: 6.75 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# GeGLU\n",
    "module = MLP(\n",
    "    cfg.dim, \n",
    "    int(cfg.dim * cfg.mlp_hidden_mult * 2/3), \n",
    "    cfg.dim, \n",
    "    'GeLU', \n",
    "    gated=True, \n",
    "    bias=False, \n",
    "    dropout_rate = 0.1\n",
    ").to(cfg.device)\n",
    "print(sum(p.numel() for p in module.parameters())/1e3, 'K parameters')\n",
    "print(module)\n",
    "module.enable_logging()\n",
    "\n",
    "x = torch.randn(32,cfg.max_seq_len,cfg.dim).to(cfg.device)\n",
    "output = module(x, training=True)\n",
    "module.disable_logging()\n",
    "del module, x, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c0748fa3-3230-4dd7-a768-1256ea72e8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.192 K parameters\n",
      "MLP(\n",
      "  (Wup): Linear(in_features=32, out_features=128, bias=False)\n",
      "  (Wdown): Linear(in_features=128, out_features=32, bias=False)\n",
      "  (nonlinearity): ReLU()\n",
      ")\n",
      "\n",
      "==========Entering MLP.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting MLP.forward==========\n",
      "CPU times: user 6.4 ms, sys: 2.12 ms, total: 8.52 ms\n",
      "Wall time: 6.51 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# not gated, testing every other nonlinearity\n",
    "module = MLP(\n",
    "    cfg.dim, \n",
    "    cfg.dim * cfg.mlp_hidden_mult, \n",
    "    cfg.dim, \n",
    "    'ReLU', \n",
    "    gated=False, \n",
    "    bias=False, \n",
    "    dropout_rate = 0.1\n",
    ").to(cfg.device)\n",
    "print(sum(p.numel() for p in module.parameters())/1e3, 'K parameters')\n",
    "print(module)\n",
    "module.enable_logging()\n",
    "\n",
    "x = torch.randn(32,cfg.max_seq_len,cfg.dim).to(cfg.device)\n",
    "output = module(x, training=True)\n",
    "module.disable_logging()\n",
    "del module, x, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd3a502f-4646-4a02-9412-372482af9fa0",
   "metadata": {},
   "source": [
    "# ResidualLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5a21d708-af47-4f32-b111-08efedc584f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.layer import Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c886661d-5a26-4787-93d1-c3c8c6b1c02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.36 K parameters\n",
      "Layer(\n",
      "  (pre_self_attn_norm): Norm()\n",
      "  (self_attn): MQA(\n",
      "    (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "    (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "    (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "    (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      "  )\n",
      "  (pre_mlp_norm): Norm()\n",
      "  (mlp): MLP(\n",
      "    (Wup): Linear(in_features=32, out_features=85, bias=False)\n",
      "    (Wgate): Linear(in_features=32, out_features=85, bias=False)\n",
      "    (Wdown): Linear(in_features=85, out_features=32, bias=False)\n",
      "    (nonlinearity): SiLU()\n",
      "  )\n",
      ")\n",
      "\n",
      "==========Entering Layer.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([128, 8])\n",
      "Tensor 'mask' shape: torch.Size([128, 128])\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Other-type 'y': Type=NoneType, Value=None\n",
      "Integer 'training': Value=True\n",
      "\n",
      "==========Entering Layer.self_attn_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([128, 8])\n",
      "Tensor 'mask' shape: torch.Size([128, 128])\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Layer.self_attn_connect==========\n",
      "\n",
      "==========Entering Layer.mlp_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Layer.mlp_connect==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Layer.forward==========\n",
      "CPU times: user 22.3 ms, sys: 6.34 ms, total: 28.6 ms\n",
      "Wall time: 17.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# TRAINING w/ only self-attention\n",
    "module = Layer(cfg).to(cfg.device)\n",
    "print(sum(p.numel() for p in module.parameters())/1e3, 'K parameters')\n",
    "print(module)\n",
    "\n",
    "module.enable_logging()\n",
    "#module.disable_function_logging('self_attn_connect')\n",
    "#module.disable_function_logging('mlp_connect')\n",
    "### enabling printing for sub-modules\n",
    "#module.pre_attn_norm.enable_logging()\n",
    "#module.attn.enable_logging()\n",
    "#module.post_attn_norm.enable_logging()\n",
    "#module.pre_mlp_norm.enable_logging()\n",
    "#module.mlp.enable_logging()\n",
    "#module.post_mlp_norm.enable_logging()\n",
    "\n",
    "# precompute RoPE frequencies, causal mask, and dummy input data\n",
    "freqs_cis = precompute_freqs_cis(\n",
    "    cfg.head_dim,\n",
    "    cfg.max_seq_len,\n",
    "    cfg.theta\n",
    ").to(cfg.device)\n",
    "mask = torch.full(\n",
    "    (cfg.max_seq_len, cfg.max_seq_len),\n",
    "    float(\"-inf\"),\n",
    "    device=cfg.device\n",
    ")\n",
    "mask = torch.triu(mask, diagonal=1)\n",
    "x = torch.randn(32,cfg.max_seq_len,cfg.dim).to(cfg.device)\n",
    "\n",
    "output = module(x, freqs_cis, mask, training=True)\n",
    "module.disable_logging()\n",
    "del module, freqs_cis, mask, x, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f534ab4-a150-42db-8c89-5e8d3d0c06a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.36 K parameters\n",
      "Layer(\n",
      "  (pre_self_attn_norm): Norm()\n",
      "  (self_attn): MQA(\n",
      "    (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "    (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "    (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "    (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      "  )\n",
      "  (pre_mlp_norm): Norm()\n",
      "  (mlp): MLP(\n",
      "    (Wup): Linear(in_features=32, out_features=85, bias=False)\n",
      "    (Wgate): Linear(in_features=32, out_features=85, bias=False)\n",
      "    (Wdown): Linear(in_features=85, out_features=32, bias=False)\n",
      "    (nonlinearity): SiLU()\n",
      "  )\n",
      ")\n",
      "\n",
      "==========Entering Layer.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([1, 32, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([32, 8])\n",
      "Tensor 'mask' shape: torch.Size([32, 74])\n",
      "Integer 'cache_len': Value=42\n",
      "Other-type 'y': Type=NoneType, Value=None\n",
      "Integer 'training': Value=False\n",
      "\n",
      "==========Entering Layer.self_attn_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([1, 32, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([32, 8])\n",
      "Tensor 'mask' shape: torch.Size([32, 74])\n",
      "Integer 'cache_len': Value=42\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 32, 32])\n",
      "==========Exiting Layer.self_attn_connect==========\n",
      "\n",
      "==========Entering Layer.mlp_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([1, 32, 32])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 32, 32])\n",
      "==========Exiting Layer.mlp_connect==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 32, 32])\n",
      "==========Exiting Layer.forward==========\n",
      "CPU times: user 2.67 ms, sys: 1.43 ms, total: 4.1 ms\n",
      "Wall time: 3.18 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# INFERENCE\n",
    "module = Layer(cfg).to(cfg.device)\n",
    "print(sum(p.numel() for p in module.parameters())/1e3, 'K parameters')\n",
    "print(module)\n",
    "\n",
    "module.enable_logging()\n",
    "#module.disable_function_logging('self_attn_connect')\n",
    "#module.disable_function_logging('mlp_connect')\n",
    "#module.pre_attn_norm.enable_logging()\n",
    "#module.attn.enable_logging()\n",
    "#module.post_attn_norm.enable_logging()\n",
    "#module.pre_mlp_norm.enable_logging()\n",
    "#module.mlp.enable_logging()\n",
    "#module.post_mlp_norm.enable_logging()\n",
    "\n",
    "# precompute RoPE frequencies, causal mask, and dummy input data\n",
    "freqs_cis = precompute_freqs_cis(\n",
    "    cfg.head_dim,\n",
    "    cfg.max_seq_len,\n",
    "    cfg.theta\n",
    ").to(cfg.device)\n",
    "mask = torch.full(\n",
    "    (cfg.max_seq_len, cfg.max_seq_len),\n",
    "    float(\"-inf\"),\n",
    "    device=cfg.device\n",
    ")\n",
    "mask = torch.triu(mask, diagonal=1)\n",
    "# setting up for kv caching\n",
    "cache_len = cfg.max_seq_len // 3\n",
    "context_chunk_len = cfg.max_seq_len // 4\n",
    "seq_len = cache_len + context_chunk_len\n",
    "# need to extend the mask with zeros for the cached values\n",
    "mask = mask[:context_chunk_len, :context_chunk_len]\n",
    "mask = torch.hstack(\n",
    "            [torch.zeros((context_chunk_len, cache_len)), mask]\n",
    "        )\n",
    "# these don't use seq_len because those entries should already be in the kv cache\n",
    "freqs_cis = freqs_cis[:context_chunk_len]\n",
    "x = torch.randn(1,context_chunk_len,cfg.dim).to(cfg.device)\n",
    "\n",
    "output = module(x, freqs_cis, mask, cache_len)\n",
    "module.disable_logging()\n",
    "del module, freqs_cis, mask, cache_len, context_chunk_len, seq_len, x, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a0086e57-b21e-47e5-8061-6b40e57eb25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.56 K parameters\n",
      "Layer(\n",
      "  (pre_self_attn_norm): Norm()\n",
      "  (self_attn): MQA(\n",
      "    (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "    (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "    (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "    (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      "  )\n",
      "  (pre_future_sight_norm_x): Norm()\n",
      "  (pre_future_sight_norm_y): Norm()\n",
      "  (future_sight): futureSightMQA(\n",
      "    (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "    (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "    (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "    (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      "  )\n",
      "  (pre_mlp_norm): Norm()\n",
      "  (mlp): MLP(\n",
      "    (Wup): Linear(in_features=32, out_features=85, bias=False)\n",
      "    (Wgate): Linear(in_features=32, out_features=85, bias=False)\n",
      "    (Wdown): Linear(in_features=85, out_features=32, bias=False)\n",
      "    (nonlinearity): SiLU()\n",
      "  )\n",
      ")\n",
      "\n",
      "==========Entering Layer.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([128, 8])\n",
      "Tensor 'mask' shape: torch.Size([128, 128])\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Tensor 'y' shape: torch.Size([32, 128, 3, 32])\n",
      "Integer 'training': Value=True\n",
      "\n",
      "==========Entering Layer.self_attn_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([128, 8])\n",
      "Tensor 'mask' shape: torch.Size([128, 128])\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Layer.self_attn_connect==========\n",
      "\n",
      "==========Entering Layer.future_sight_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'y' shape: torch.Size([32, 128, 3, 32])\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Layer.future_sight_connect==========\n",
      "\n",
      "==========Entering Layer.mlp_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Layer.mlp_connect==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Layer.forward==========\n",
      "CPU times: user 34.9 ms, sys: 10.7 ms, total: 45.7 ms\n",
      "Wall time: 28.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Layer w/ future sight cross-attention and w/ kv caching in the self-attention enabled while TRAINING\n",
    "module = Layer(cfg, cross_attn=True).to(cfg.device)\n",
    "print(sum(p.numel() for p in module.parameters())/1e3, 'K parameters')\n",
    "print(module)\n",
    "\n",
    "module.enable_logging()\n",
    "#module.disable_function_logging('self_attn_connect')\n",
    "#module.disable_function_logging('future_sight_connect')\n",
    "#module.disable_function_logging('mlp_connect')\n",
    "### enabling printing for sub-modules\n",
    "#module.pre_self_attn_norm.enable_logging()\n",
    "#module.self_attn.enable_logging()\n",
    "#module.post_self_attn_norm.enable_logging()\n",
    "#module.pre_future_sight_norm_x.enable_logging()\n",
    "#module.pre_future_sight_norm_z.enable_logging()\n",
    "#module.future_sight.enable_logging()\n",
    "#module.post_future_sight_norm.enable_logging()\n",
    "#module.pre_mlp_norm.enable_logging()\n",
    "#module.mlp.enable_logging()\n",
    "#module.post_mlp_norm.enable_logging()\n",
    "\n",
    "# precompute RoPE frequencies, causal mask, and dummy input data\n",
    "freqs_cis = precompute_freqs_cis(\n",
    "    cfg.head_dim,\n",
    "    cfg.max_seq_len,\n",
    "    cfg.theta\n",
    ").to(cfg.device)\n",
    "mask = torch.full(\n",
    "    (cfg.max_seq_len, cfg.max_seq_len),\n",
    "    float(\"-inf\"),\n",
    "    device=cfg.device\n",
    ")\n",
    "mask = torch.triu(mask, diagonal=1)\n",
    "x = torch.randn(32,cfg.max_seq_len,cfg.dim).to(cfg.device)\n",
    "y = torch.randn(32,cfg.max_seq_len, 3, cfg.dim).to(cfg.device)\n",
    "\n",
    "output = module(x, freqs_cis, mask, y=y, training=True)\n",
    "module.disable_logging()\n",
    "del module, freqs_cis, mask, x, y, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7d5cbd18-8098-4a27-9311-4980810b4e5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.56 K parameters\n",
      "Layer(\n",
      "  (pre_self_attn_norm): Norm()\n",
      "  (self_attn): MQA(\n",
      "    (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "    (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "    (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "    (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      "  )\n",
      "  (pre_future_sight_norm_x): Norm()\n",
      "  (pre_future_sight_norm_y): Norm()\n",
      "  (future_sight): futureSightMQA(\n",
      "    (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "    (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "    (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "    (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      "  )\n",
      "  (pre_mlp_norm): Norm()\n",
      "  (mlp): MLP(\n",
      "    (Wup): Linear(in_features=32, out_features=85, bias=False)\n",
      "    (Wgate): Linear(in_features=32, out_features=85, bias=False)\n",
      "    (Wdown): Linear(in_features=85, out_features=32, bias=False)\n",
      "    (nonlinearity): SiLU()\n",
      "  )\n",
      ")\n",
      "\n",
      "==========Entering Layer.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([128, 8])\n",
      "Tensor 'mask' shape: torch.Size([128, 128])\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Tensor 'y' shape: torch.Size([32, 128, 3, 32])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "==========Entering Layer.self_attn_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([128, 8])\n",
      "Tensor 'mask' shape: torch.Size([128, 128])\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Layer.self_attn_connect==========\n",
      "\n",
      "==========Entering Layer.future_sight_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'y' shape: torch.Size([32, 128, 3, 32])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Layer.future_sight_connect==========\n",
      "\n",
      "==========Entering Layer.mlp_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Layer.mlp_connect==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Layer.forward==========\n",
      "CPU times: user 27.3 ms, sys: 9.91 ms, total: 37.2 ms\n",
      "Wall time: 21.4 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Layer w/ future sight cross-attention and w/o kv caching in the self-attention enabled during INFERENCE\n",
    "module = Layer(cfg, cross_attn = True, kv_cache = False).to(cfg.device)\n",
    "print(sum(p.numel() for p in module.parameters())/1e3, 'K parameters')\n",
    "print(module)\n",
    "\n",
    "module.enable_logging()\n",
    "#module.disable_function_logging('self_attn_connect')\n",
    "#module.disable_function_logging('future_sight_connect')\n",
    "#module.disable_function_logging('mlp_connect')\n",
    "#module.pre_self_attn_norm.enable_logging()\n",
    "#module.self_attn.enable_logging()\n",
    "#module.post_self_attn_norm.enable_logging()\n",
    "#module.pre_future_sight_norm_x.enable_logging()\n",
    "#module.pre_future_sight_norm_z.enable_logging()\n",
    "#module.future_sight.enable_logging()\n",
    "#module.post_future_sight_norm.enable_logging()\n",
    "#module.pre_mlp_norm.enable_logging()\n",
    "#module.mlp.enable_logging()\n",
    "#module.post_mlp_norm.enable_logging()\n",
    "\n",
    "# precompute RoPE frequencies, causal mask, and dummy input data\n",
    "freqs_cis = precompute_freqs_cis(cfg.head_dim,\n",
    "                                 cfg.max_seq_len,\n",
    "                                 cfg.theta).to(cfg.device)\n",
    "mask = torch.full((cfg.max_seq_len, cfg.max_seq_len),\n",
    "                  float(\"-inf\"),\n",
    "                  device=cfg.device)\n",
    "mask = torch.triu(mask, diagonal=1)\n",
    "x = torch.randn(32,cfg.max_seq_len,cfg.dim).to(cfg.device)\n",
    "y = torch.randn(32,cfg.max_seq_len, 3, cfg.dim).to(cfg.device)\n",
    "\n",
    "output = module(x, freqs_cis, mask, y=y)\n",
    "module.disable_logging()\n",
    "del module, freqs_cis, mask, x, y, output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c677ac2b-06d0-4895-b718-2bc664613c98",
   "metadata": {},
   "source": [
    "# Full Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "655a1fec-4e32-4c7a-86e0-1390a03e88e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.model import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ccc88d4-c650-43d3-85ee-e68152cb2e82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110.752 K parameters\n",
      "Model(\n",
      "  (token_embedder): Embedding(1027, 32)\n",
      "  (body_layers): ModuleList(\n",
      "    (0-2): 3 x Layer(\n",
      "      (pre_self_attn_norm): Norm()\n",
      "      (self_attn): MQA(\n",
      "        (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "        (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "        (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "        (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      "      )\n",
      "      (pre_mlp_norm): Norm()\n",
      "      (mlp): MLP(\n",
      "        (Wup): Linear(in_features=32, out_features=85, bias=False)\n",
      "        (Wgate): Linear(in_features=32, out_features=85, bias=False)\n",
      "        (Wdown): Linear(in_features=85, out_features=32, bias=False)\n",
      "        (nonlinearity): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (first_fs_layer): Layer(\n",
      "    (pre_self_attn_norm): Norm()\n",
      "    (self_attn): MQA(\n",
      "      (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "      (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "      (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "      (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      "    )\n",
      "    (pre_future_sight_norm_x): Norm()\n",
      "    (pre_future_sight_norm_y): Norm()\n",
      "    (future_sight): futureSightMQA(\n",
      "      (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "      (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "      (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "      (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      "    )\n",
      "    (pre_mlp_norm): Norm()\n",
      "    (mlp): MLP(\n",
      "      (Wup): Linear(in_features=32, out_features=85, bias=False)\n",
      "      (Wgate): Linear(in_features=32, out_features=85, bias=False)\n",
      "      (Wdown): Linear(in_features=85, out_features=32, bias=False)\n",
      "      (nonlinearity): SiLU()\n",
      "    )\n",
      "  )\n",
      "  (fs_layers): ModuleList(\n",
      "    (0-1): 2 x Layer(\n",
      "      (pre_self_attn_norm): Norm()\n",
      "      (self_attn): MQA(\n",
      "        (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "        (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "        (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "        (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      "      )\n",
      "      (pre_future_sight_norm_x): Norm()\n",
      "      (pre_future_sight_norm_y): Norm()\n",
      "      (future_sight): futureSightMQA(\n",
      "        (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "        (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "        (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "        (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      "      )\n",
      "      (pre_mlp_norm): Norm()\n",
      "      (mlp): MLP(\n",
      "        (Wup): Linear(in_features=32, out_features=85, bias=False)\n",
      "        (Wgate): Linear(in_features=32, out_features=85, bias=False)\n",
      "        (Wdown): Linear(in_features=85, out_features=32, bias=False)\n",
      "        (nonlinearity): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_pool_norm): Norm()\n",
      "  (pooler): PoolingHub(\n",
      "    (pooler): SumPooling()\n",
      "  )\n",
      "  (output_projection): Sequential(\n",
      "    (0): Norm()\n",
      "    (1): Linear(in_features=32, out_features=1027, bias=False)\n",
      "  )\n",
      "  (fs_criterion): BCEWithLogitsLoss()\n",
      "  (ntp_criterion): CrossEntropyLoss()\n",
      ")\n",
      "\n",
      "==========Entering Model.forward==========\n",
      "Inputs:\n",
      "Tensor 'input_token_ids' shape: torch.Size([32, 128])\n",
      "Integer 'cache_len': Value=0\n",
      "Tensor 'target_token_ids' shape: torch.Size([32, 128])\n",
      "\n",
      "==========Entering Model.forward_train==========\n",
      "Inputs:\n",
      "Tensor 'input_token_ids' shape: torch.Size([32, 128])\n",
      "Tensor 'target_token_ids' shape: torch.Size([32, 128])\n",
      "\n",
      "==========Entering Layer.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([128, 8])\n",
      "Tensor 'mask' shape: torch.Size([128, 128])\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Other-type 'y': Type=NoneType, Value=None\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Layer.forward==========\n",
      "\n",
      "==========Entering Layer.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([128, 8])\n",
      "Tensor 'mask' shape: torch.Size([128, 128])\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Tensor 'y' shape: torch.Size([32, 128, 1, 32])\n",
      "Integer 'training': Value=True\n",
      "\n",
      "==========Entering Layer.self_attn_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([128, 8])\n",
      "Tensor 'mask' shape: torch.Size([128, 128])\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Layer.self_attn_connect==========\n",
      "\n",
      "==========Entering Layer.future_sight_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'y' shape: torch.Size([32, 128, 1, 32])\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Layer.future_sight_connect==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Layer.forward==========\n",
      "\n",
      "==========Entering Layer.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([128, 8])\n",
      "Tensor 'mask' shape: torch.Size([128, 128])\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Tensor 'y' shape: torch.Size([32, 128, 1, 32])\n",
      "Integer 'training': Value=True\n",
      "\n",
      "==========Entering Layer.self_attn_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([128, 8])\n",
      "Tensor 'mask' shape: torch.Size([128, 128])\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Layer.self_attn_connect==========\n",
      "\n",
      "==========Entering Layer.future_sight_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'y' shape: torch.Size([32, 128, 1, 32])\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Layer.future_sight_connect==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Layer.forward==========\n",
      "\n",
      "==========Entering Layer.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([128, 8])\n",
      "Tensor 'mask' shape: torch.Size([128, 128])\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Tensor 'y' shape: torch.Size([32, 128, 2, 32])\n",
      "Integer 'training': Value=True\n",
      "\n",
      "==========Entering Layer.self_attn_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([128, 8])\n",
      "Tensor 'mask' shape: torch.Size([128, 128])\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Layer.self_attn_connect==========\n",
      "\n",
      "==========Entering Layer.future_sight_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([32, 128, 32])\n",
      "Tensor 'y' shape: torch.Size([32, 128, 2, 32])\n",
      "Integer 'training': Value=True\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Layer.future_sight_connect==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([32, 128, 32])\n",
      "==========Exiting Layer.forward==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 128, 1027])\n",
      "Tensor 'output[1]' shape: torch.Size([])\n",
      "==========Exiting Model.forward_train==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([32, 128, 1027])\n",
      "Tensor 'output[1]' shape: torch.Size([])\n",
      "==========Exiting Model.forward==========\n",
      "torch.Size([32, 128, 1027]) tensor(9.2984, grad_fn=<AddBackward0>)\n",
      "CPU times: user 434 ms, sys: 265 ms, total: 699 ms\n",
      "Wall time: 271 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# TRAINING\n",
    "module = Model(cfg).to(cfg.device)\n",
    "print(sum(p.numel() for p in module.parameters())/1e3, 'K parameters')\n",
    "print(module)\n",
    "\n",
    "module.enable_logging()\n",
    "### enabling printing for sub-modules\n",
    "module.body_layers[0].enable_logging()\n",
    "module.body_layers[0].disable_function_logging('self_attn_connect') # disabling some functions of some sub-modules\n",
    "module.body_layers[0].disable_function_logging('mlp_connect')\n",
    "module.first_fs_layer.enable_logging()\n",
    "module.first_fs_layer.disable_function_logging('mlp_connect')\n",
    "module.fs_layers[0].enable_logging()\n",
    "module.fs_layers[0].disable_function_logging('mlp_connect')\n",
    "module.fs_layers[-1].enable_logging()\n",
    "module.fs_layers[-1].disable_function_logging('mlp_connect')\n",
    "\n",
    "input_token_ids = torch.randint(tokenizer.vocab_len, (32, cfg.max_seq_len)).to(cfg.device)\n",
    "target_token_ids = torch.randint(tokenizer.vocab_len, (32, cfg.max_seq_len)).to(cfg.device)\n",
    "\n",
    "output, loss = module(input_token_ids, target_token_ids=target_token_ids)\n",
    "print(output.shape, loss)\n",
    "del module, input_token_ids, target_token_ids, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1a92340e-55a2-43c8-be2c-5b6c844f98a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110.752 K parameters\n",
      "Model(\n",
      "  (token_embedder): Embedding(1027, 32)\n",
      "  (body_layers): ModuleList(\n",
      "    (0-2): 3 x Layer(\n",
      "      (pre_self_attn_norm): Norm()\n",
      "      (self_attn): MQA(\n",
      "        (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "        (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "        (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "        (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      "      )\n",
      "      (pre_mlp_norm): Norm()\n",
      "      (mlp): MLP(\n",
      "        (Wup): Linear(in_features=32, out_features=85, bias=False)\n",
      "        (Wgate): Linear(in_features=32, out_features=85, bias=False)\n",
      "        (Wdown): Linear(in_features=85, out_features=32, bias=False)\n",
      "        (nonlinearity): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (first_fs_layer): Layer(\n",
      "    (pre_self_attn_norm): Norm()\n",
      "    (self_attn): MQA(\n",
      "      (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "      (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "      (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "      (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      "    )\n",
      "    (pre_future_sight_norm_x): Norm()\n",
      "    (pre_future_sight_norm_y): Norm()\n",
      "    (future_sight): futureSightMQA(\n",
      "      (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "      (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "      (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "      (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      "    )\n",
      "    (pre_mlp_norm): Norm()\n",
      "    (mlp): MLP(\n",
      "      (Wup): Linear(in_features=32, out_features=85, bias=False)\n",
      "      (Wgate): Linear(in_features=32, out_features=85, bias=False)\n",
      "      (Wdown): Linear(in_features=85, out_features=32, bias=False)\n",
      "      (nonlinearity): SiLU()\n",
      "    )\n",
      "  )\n",
      "  (fs_layers): ModuleList(\n",
      "    (0-1): 2 x Layer(\n",
      "      (pre_self_attn_norm): Norm()\n",
      "      (self_attn): MQA(\n",
      "        (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "        (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "        (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "        (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      "      )\n",
      "      (pre_future_sight_norm_x): Norm()\n",
      "      (pre_future_sight_norm_y): Norm()\n",
      "      (future_sight): futureSightMQA(\n",
      "        (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "        (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "        (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "        (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      "      )\n",
      "      (pre_mlp_norm): Norm()\n",
      "      (mlp): MLP(\n",
      "        (Wup): Linear(in_features=32, out_features=85, bias=False)\n",
      "        (Wgate): Linear(in_features=32, out_features=85, bias=False)\n",
      "        (Wdown): Linear(in_features=85, out_features=32, bias=False)\n",
      "        (nonlinearity): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_pool_norm): Norm()\n",
      "  (pooler): PoolingHub(\n",
      "    (pooler): SumPooling()\n",
      "  )\n",
      "  (output_projection): Sequential(\n",
      "    (0): Norm()\n",
      "    (1): Linear(in_features=32, out_features=1027, bias=False)\n",
      "  )\n",
      "  (fs_criterion): BCEWithLogitsLoss()\n",
      "  (ntp_criterion): CrossEntropyLoss()\n",
      ")\n",
      "\n",
      "==========Entering Model.forward==========\n",
      "Inputs:\n",
      "Tensor 'input_token_ids' shape: torch.Size([1, 32])\n",
      "Integer 'cache_len': Value=0\n",
      "Other-type 'target_token_ids': Type=NoneType, Value=None\n",
      "\n",
      "==========Entering Model.forward_inference==========\n",
      "Inputs:\n",
      "Tensor 'input_token_ids' shape: torch.Size([1, 32])\n",
      "Integer 'cache_len': Value=0\n",
      "\n",
      "==========Entering Layer.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([1, 32, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([32, 8])\n",
      "Tensor 'mask' shape: torch.Size([32, 32])\n",
      "Integer 'cache_len': Value=0\n",
      "Other-type 'y': Type=NoneType, Value=None\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 32, 32])\n",
      "==========Exiting Layer.forward==========\n",
      "\n",
      "==========Entering Layer.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([1, 32, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([32, 8])\n",
      "Tensor 'mask' shape: torch.Size([32, 32])\n",
      "Integer 'cache_len': Value=0\n",
      "Tensor 'y' shape: torch.Size([1, 32, 1, 32])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "==========Entering Layer.self_attn_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([1, 32, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([32, 8])\n",
      "Tensor 'mask' shape: torch.Size([32, 32])\n",
      "Integer 'cache_len': Value=0\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 32, 32])\n",
      "==========Exiting Layer.self_attn_connect==========\n",
      "\n",
      "==========Entering Layer.future_sight_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([1, 32, 32])\n",
      "Tensor 'y' shape: torch.Size([1, 32, 1, 32])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 32, 32])\n",
      "==========Exiting Layer.future_sight_connect==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 32, 32])\n",
      "==========Exiting Layer.forward==========\n",
      "\n",
      "==========Entering Layer.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([1, 32, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([32, 8])\n",
      "Tensor 'mask' shape: torch.Size([32, 32])\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Tensor 'y' shape: torch.Size([1, 32, 1, 32])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "==========Entering Layer.self_attn_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([1, 32, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([32, 8])\n",
      "Tensor 'mask' shape: torch.Size([32, 32])\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 32, 32])\n",
      "==========Exiting Layer.self_attn_connect==========\n",
      "\n",
      "==========Entering Layer.future_sight_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([1, 32, 32])\n",
      "Tensor 'y' shape: torch.Size([1, 32, 1, 32])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 32, 32])\n",
      "==========Exiting Layer.future_sight_connect==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 32, 32])\n",
      "==========Exiting Layer.forward==========\n",
      "\n",
      "==========Entering Layer.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([1, 32, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([32, 8])\n",
      "Tensor 'mask' shape: torch.Size([32, 32])\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Tensor 'y' shape: torch.Size([1, 32, 1, 32])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "==========Entering Layer.self_attn_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([1, 32, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([32, 8])\n",
      "Tensor 'mask' shape: torch.Size([32, 32])\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 32, 32])\n",
      "==========Exiting Layer.self_attn_connect==========\n",
      "\n",
      "==========Entering Layer.future_sight_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([1, 32, 32])\n",
      "Tensor 'y' shape: torch.Size([1, 32, 1, 32])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 32, 32])\n",
      "==========Exiting Layer.future_sight_connect==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 32, 32])\n",
      "==========Exiting Layer.forward==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([1, 32, 1027])\n",
      "Other-type 'output[1]': Type=NoneType, Value=None\n",
      "==========Exiting Model.forward_inference==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output[0]' shape: torch.Size([1, 32, 1027])\n",
      "Other-type 'output[1]': Type=NoneType, Value=None\n",
      "==========Exiting Model.forward==========\n",
      "torch.Size([1, 32, 1027])\n",
      "CPU times: user 18.5 ms, sys: 4.93 ms, total: 23.4 ms\n",
      "Wall time: 21.8 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Inference w/out kv caching\n",
    "module = Model(cfg).to(cfg.device)\n",
    "print(sum(p.numel() for p in module.parameters())/1e3, 'K parameters')\n",
    "print(module)\n",
    "\n",
    "module.enable_logging()\n",
    "### enabling printing for sub-modules\n",
    "module.body_layers[0].enable_logging()\n",
    "module.body_layers[0].disable_function_logging('self_attn_connect') # disabling some functions of some sub-modules\n",
    "module.body_layers[0].disable_function_logging('mlp_connect')\n",
    "module.first_fs_layer.enable_logging()\n",
    "module.first_fs_layer.disable_function_logging('mlp_connect')\n",
    "module.fs_layers[0].enable_logging()\n",
    "module.fs_layers[0].disable_function_logging('mlp_connect')\n",
    "module.fs_layers[-1].enable_logging()\n",
    "module.fs_layers[-1].disable_function_logging('mlp_connect')\n",
    "\n",
    "input_token_ids = torch.randint(tokenizer.vocab_len, (1, cfg.max_seq_len // 4)).to(cfg.device)\n",
    "\n",
    "output, _ = module(input_token_ids)\n",
    "print(output.shape)\n",
    "del module, input_token_ids, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "316598a6-1ba9-4a26-962f-16c0802a698e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110.752 K parameters\n",
      "Model(\n",
      "  (token_embedder): Embedding(1027, 32)\n",
      "  (body_layers): ModuleList(\n",
      "    (0-2): 3 x Layer(\n",
      "      (pre_self_attn_norm): Norm()\n",
      "      (self_attn): MQA(\n",
      "        (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "        (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "        (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "        (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      "      )\n",
      "      (pre_mlp_norm): Norm()\n",
      "      (mlp): MLP(\n",
      "        (Wup): Linear(in_features=32, out_features=85, bias=False)\n",
      "        (Wgate): Linear(in_features=32, out_features=85, bias=False)\n",
      "        (Wdown): Linear(in_features=85, out_features=32, bias=False)\n",
      "        (nonlinearity): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (first_fs_layer): Layer(\n",
      "    (pre_self_attn_norm): Norm()\n",
      "    (self_attn): MQA(\n",
      "      (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "      (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "      (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "      (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      "    )\n",
      "    (pre_future_sight_norm_x): Norm()\n",
      "    (pre_future_sight_norm_y): Norm()\n",
      "    (future_sight): futureSightMQA(\n",
      "      (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "      (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "      (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "      (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      "    )\n",
      "    (pre_mlp_norm): Norm()\n",
      "    (mlp): MLP(\n",
      "      (Wup): Linear(in_features=32, out_features=85, bias=False)\n",
      "      (Wgate): Linear(in_features=32, out_features=85, bias=False)\n",
      "      (Wdown): Linear(in_features=85, out_features=32, bias=False)\n",
      "      (nonlinearity): SiLU()\n",
      "    )\n",
      "  )\n",
      "  (fs_layers): ModuleList(\n",
      "    (0-1): 2 x Layer(\n",
      "      (pre_self_attn_norm): Norm()\n",
      "      (self_attn): MQA(\n",
      "        (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "        (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "        (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "        (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      "      )\n",
      "      (pre_future_sight_norm_x): Norm()\n",
      "      (pre_future_sight_norm_y): Norm()\n",
      "      (future_sight): futureSightMQA(\n",
      "        (Wq): Linear(in_features=32, out_features=32, bias=False)\n",
      "        (Wk): Linear(in_features=32, out_features=16, bias=False)\n",
      "        (Wv): Linear(in_features=32, out_features=16, bias=False)\n",
      "        (Wo): Linear(in_features=32, out_features=32, bias=False)\n",
      "      )\n",
      "      (pre_mlp_norm): Norm()\n",
      "      (mlp): MLP(\n",
      "        (Wup): Linear(in_features=32, out_features=85, bias=False)\n",
      "        (Wgate): Linear(in_features=32, out_features=85, bias=False)\n",
      "        (Wdown): Linear(in_features=85, out_features=32, bias=False)\n",
      "        (nonlinearity): SiLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pre_pool_norm): Norm()\n",
      "  (pooler): PoolingHub(\n",
      "    (pooler): SumPooling()\n",
      "  )\n",
      "  (output_projection): Sequential(\n",
      "    (0): Norm()\n",
      "    (1): Linear(in_features=32, out_features=1027, bias=False)\n",
      "  )\n",
      "  (fs_criterion): BCEWithLogitsLoss()\n",
      "  (ntp_criterion): CrossEntropyLoss()\n",
      ")\n",
      "\n",
      "==========Entering Model.forward==========\n",
      "Inputs:\n",
      "Tensor 'inputs' shape: torch.Size([1, 32])\n",
      "Integer 'cache_len': Value=42\n",
      "Other-type 'targets': Type=NoneType, Value=None\n",
      "\n",
      "==========Entering Model.forward_inference==========\n",
      "Inputs:\n",
      "Tensor 'inputs' shape: torch.Size([1, 32])\n",
      "Integer 'cache_len': Value=42\n",
      "\n",
      "==========Entering Layer.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([1, 32, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([32, 8])\n",
      "Tensor 'mask' shape: torch.Size([32, 74])\n",
      "Integer 'cache_len': Value=42\n",
      "Other-type 'y': Type=NoneType, Value=None\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 32, 32])\n",
      "==========Exiting Layer.forward==========\n",
      "\n",
      "==========Entering Layer.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([1, 32, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([32, 8])\n",
      "Tensor 'mask' shape: torch.Size([32, 74])\n",
      "Integer 'cache_len': Value=42\n",
      "Tensor 'y' shape: torch.Size([1, 32, 1, 32])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "==========Entering Layer.self_attn_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([1, 32, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([32, 8])\n",
      "Tensor 'mask' shape: torch.Size([32, 74])\n",
      "Integer 'cache_len': Value=42\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 32, 32])\n",
      "==========Exiting Layer.self_attn_connect==========\n",
      "\n",
      "==========Entering Layer.future_sight_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([1, 32, 32])\n",
      "Tensor 'y' shape: torch.Size([1, 32, 1, 32])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 32, 32])\n",
      "==========Exiting Layer.future_sight_connect==========\n",
      "\n",
      "Outputs:\n",
      "Tensor 'output' shape: torch.Size([1, 32, 32])\n",
      "==========Exiting Layer.forward==========\n",
      "\n",
      "==========Entering Layer.forward==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([1, 32, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([32, 8])\n",
      "Tensor 'mask' shape: torch.Size([32, 74])\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Tensor 'y' shape: torch.Size([1, 32, 1, 32])\n",
      "Integer 'training': Value=False\n",
      "\n",
      "==========Entering Layer.self_attn_connect==========\n",
      "Inputs:\n",
      "Tensor 'x' shape: torch.Size([1, 32, 32])\n",
      "Tensor 'freqs_cis' shape: torch.Size([32, 8])\n",
      "Tensor 'mask' shape: torch.Size([32, 74])\n",
      "Other-type 'cache_len': Type=NoneType, Value=None\n",
      "Integer 'training': Value=False\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (32) must match the size of tensor b (74) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[0;32m<timed exec>:20\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/local-repos/micro-GPT-sandbox/models/FutureFormer/modules/logging.py:52\u001b[0m, in \u001b[0;36mlog_io.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     50\u001b[0m         log_item(value, name)\n\u001b[0;32m---> 52\u001b[0m result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOutputs:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/local-repos/micro-GPT-sandbox/models/FutureFormer/modules/model.py:85\u001b[0m, in \u001b[0;36mModel.forward\u001b[0;34m(self, inputs, cache_len, targets)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;129m@log_io\u001b[39m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28mself\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     83\u001b[0m     targets: Optional[torch\u001b[38;5;241m.\u001b[39mTensor] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     84\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m (torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m---> 85\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_inference(inputs, cache_len) \u001b[38;5;28;01mif\u001b[39;00m targets \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mforward_train(inputs, targets)\n",
      "File \u001b[0;32m~/local-repos/micro-GPT-sandbox/models/FutureFormer/modules/logging.py:52\u001b[0m, in \u001b[0;36mlog_io.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     50\u001b[0m         log_item(value, name)\n\u001b[0;32m---> 52\u001b[0m result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOutputs:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/local-repos/micro-GPT-sandbox/models/FutureFormer/modules/model.py:190\u001b[0m, in \u001b[0;36mModel.forward_inference\u001b[0;34m(self, inputs, cache_len)\u001b[0m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m### loop thru remaining layers & their outputs\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs_layers):\n\u001b[0;32m--> 190\u001b[0m     x \u001b[38;5;241m=\u001b[39m layer(x, freqs_cis, mask, y \u001b[38;5;241m=\u001b[39m y) \u001b[38;5;66;03m# (batch_size, max_seq_len, dim)\u001b[39;00m\n\u001b[1;32m    191\u001b[0m     z \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_projection(x) \u001b[38;5;66;03m# (batch_size, max_seq_len, vocab_len)\u001b[39;00m\n\u001b[1;32m    192\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfs_periods \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/local-repos/micro-GPT-sandbox/models/FutureFormer/modules/logging.py:52\u001b[0m, in \u001b[0;36mlog_io.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     50\u001b[0m         log_item(value, name)\n\u001b[0;32m---> 52\u001b[0m result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOutputs:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/local-repos/micro-GPT-sandbox/models/FutureFormer/modules/layer.py:69\u001b[0m, in \u001b[0;36mLayer.forward\u001b[0;34m(self, x, freqs_cis, mask, cache_len, y, training)\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;129m@log_io\u001b[39m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     67\u001b[0m     training \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     68\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 69\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn_connect(x, freqs_cis, mask, cache_len, training)\n\u001b[1;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcross_attn \u001b[38;5;241m&\u001b[39m (y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m     71\u001b[0m         x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture_sight_connect(x, y, training)\n",
      "File \u001b[0;32m~/local-repos/micro-GPT-sandbox/models/FutureFormer/modules/logging.py:52\u001b[0m, in \u001b[0;36mlog_io.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     50\u001b[0m         log_item(value, name)\n\u001b[0;32m---> 52\u001b[0m result \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mOutputs:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(result, \u001b[38;5;28mtuple\u001b[39m):\n",
      "File \u001b[0;32m~/local-repos/micro-GPT-sandbox/models/FutureFormer/modules/layer.py:89\u001b[0m, in \u001b[0;36mLayer.self_attn_connect\u001b[0;34m(self, x, freqs_cis, mask, cache_len, training)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;129m@log_io\u001b[39m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mself_attn_connect\u001b[39m(\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28mself\u001b[39m, \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     86\u001b[0m     training: \u001b[38;5;28mbool\u001b[39m\n\u001b[1;32m     87\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m     88\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_self_attn_norm(x)\n\u001b[0;32m---> 89\u001b[0m     dx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mself_attn(x, x, x, freqs_cis, mask, cache_len, training) \u001b[38;5;66;03m# the 3 x's are for q, k, & v bc the module supports cross-attention\u001b[39;00m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m training: F\u001b[38;5;241m.\u001b[39mdropout(dx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout_rate)\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msecond_norm: dx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpost_self_attn_norm(dx)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/local-repos/micro-GPT-sandbox/models/FutureFormer/modules/logging.py:13\u001b[0m, in \u001b[0;36mlog_io.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Check if logging is enabled globally and for the specific function\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogging_enabled \u001b[38;5;129;01mor\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisabled_logging_functions:\n\u001b[0;32m---> 13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlog_item\u001b[39m(item, name, level\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, is_root\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m     16\u001b[0m         indent \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m    \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m level\n",
      "File \u001b[0;32m~/local-repos/micro-GPT-sandbox/models/FutureFormer/modules/mqa.py:104\u001b[0m, in \u001b[0;36mMQA.forward\u001b[0;34m(self, q, k, v, freqs_cis, mask, cache_len, training)\u001b[0m\n\u001b[1;32m    101\u001b[0m v \u001b[38;5;241m=\u001b[39m v\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)  \u001b[38;5;66;03m# (batch_size, num_q_heads, cache_len + seq_len_kv, head_dim)\u001b[39;00m\n\u001b[1;32m    103\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mattend(q, k) \u001b[38;5;66;03m# (batch_size, num_q_heads, seq_len_q, cache_len + seq_len_kv)\u001b[39;00m\n\u001b[0;32m--> 104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m: logits \u001b[38;5;241m=\u001b[39m logits \u001b[38;5;241m+\u001b[39m mask  \n\u001b[1;32m    105\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcalc_output(logits, v, training) \u001b[38;5;66;03m# (batch_size, seq_len_q, n_heads * head_dim)\u001b[39;00m\n\u001b[1;32m    107\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mWo(scores) \u001b[38;5;66;03m# (batch_size, seq_len_q, dim)\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (32) must match the size of tensor b (74) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Inference w/ kv caching\n",
    "### low key i'm thinking i just abandon kv-caching on this model for now and only bring it back if/when i decide to keep it.\n",
    "#   pretty sure it wouldn't be a difficult fix or anything but i straight up don't wanna do it\n",
    "module = Model(cfg).to(cfg.device)\n",
    "print(sum(p.numel() for p in module.parameters())/1e3, 'K parameters')\n",
    "print(module)\n",
    "\n",
    "module.enable_logging()\n",
    "### enabling printing for sub-modules\n",
    "module.body_layers[0].enable_logging()\n",
    "module.body_layers[0].disable_function_logging('self_attn_connect') # disabling some functions of some sub-modules\n",
    "module.body_layers[0].disable_function_logging('mlp_connect')\n",
    "module.first_fs_layer.enable_logging()\n",
    "module.first_fs_layer.disable_function_logging('mlp_connect')\n",
    "module.fs_layers[0].enable_logging()\n",
    "module.fs_layers[0].disable_function_logging('mlp_connect')\n",
    "module.fs_layers[-1].enable_logging()\n",
    "module.fs_layers[-1].disable_function_logging('mlp_connect')\n",
    "\n",
    "input_token_ids = torch.randint(tokenizer.vocab_len, (1, cfg.max_seq_len // 4)).to(cfg.device)\n",
    "\n",
    "output, _ = module(input_token_ids, cache_len = cfg.max_seq_len // 3)\n",
    "print(output.shape)\n",
    "del module, input_token_ids, output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83d82f9c-e531-47b5-8ffb-c8374ffb0e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
