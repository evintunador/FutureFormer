{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c04932d1-a13d-4c6c-a1ed-7efb5b83dfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79ed819d-aea5-43f6-a4c4-72495191e589",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_matrices(target_tokens, padding_token):\n",
    "    batch_size, max_seq_len = target_tokens.size()\n",
    "    matrices = []\n",
    "\n",
    "    # Length starts from 2 and doubles each iteration\n",
    "    length = 2\n",
    "    while length <= max_seq_len:\n",
    "        matrix = []\n",
    "        for i in range(max_seq_len):\n",
    "            subseq = target_tokens[:, i+1:i+1+length]  # slice the target tokens\n",
    "            \n",
    "            # If the subsequence is shorter than the required length, pad it with padding_token\n",
    "            if subseq.size(1) < length:\n",
    "                padding = torch.full((batch_size, length - subseq.size(1)), padding_token, dtype=torch.long)\n",
    "                subseq = torch.cat([subseq, padding], dim=1)\n",
    "            \n",
    "            matrix.append(subseq)\n",
    "        \n",
    "        matrices.append(torch.stack(matrix, dim=1))\n",
    "        length *= 2\n",
    "\n",
    "    return matrices\n",
    "\n",
    "# Example usage\n",
    "batch_size = 1\n",
    "max_seq_len = 15\n",
    "padding_token = 0  # or 'v' if you have a specific padding token\n",
    "target_tokens = torch.tensor([\n",
    "    [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16]\n",
    "])\n",
    "\n",
    "matrices = generate_matrices(target_tokens, padding_token)\n",
    "\n",
    "# Print the matrices to verify\n",
    "for idx, matrix in enumerate(matrices):\n",
    "    print(f\"Matrix {idx+1}:\\n{matrix}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
